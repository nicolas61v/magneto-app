// src/app/api/extract-text/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { ImageAnnotatorClient } from '@google-cloud/vision';

export async function POST(request: NextRequest) {
  const startTime = Date.now();
  console.log(`\n=== [${new Date().toISOString()}] INICIANDO EXTRACCI√ìN DE TEXTO ===`);

  try {
    const { imageUrl } = await request.json();

    if (!imageUrl) {
      console.log('‚ùå Falt√≥ imageUrl en la solicitud.');
      return NextResponse.json(
        { error: 'Se requiere URL de imagen para procesar' },
        { status: 400 }
      );
    }

    console.log('üì∏ URL de imagen recibida:', imageUrl);

    // Verificar variables de entorno
    if (
      !process.env.GOOGLE_CLOUD_PROJECT_ID ||
      !process.env.GOOGLE_CLOUD_PRIVATE_KEY ||
      !process.env.GOOGLE_CLOUD_CLIENT_EMAIL
    ) {
      console.log('‚ùå Variables de entorno faltantes para Google Vision AI.');
      return NextResponse.json(
        { error: 'Google Vision AI no est√° configurado correctamente. Faltan variables de entorno.' },
        { status: 500 }
      );
    }

    // Configurar cliente de Google Vision AI
    const client = new ImageAnnotatorClient({
      projectId: process.env.GOOGLE_CLOUD_PROJECT_ID,
      credentials: {
        client_email: process.env.GOOGLE_CLOUD_CLIENT_EMAIL,
        // Asegurarse de que los saltos de l√≠nea en la clave privada se manejen correctamente
        private_key: process.env.GOOGLE_CLOUD_PRIVATE_KEY.replace(/\\n/g, '\n'),
      },
    });

    console.log('üîß Cliente de Google Vision AI configurado.');

    let extractedText = '';
    let detectionMethod = '';

    // ===== ESTRATEGIA 1: DOCUMENT_TEXT_DETECTION (M√©todo preferido para texto denso) =====
    try {
      console.log('üìÑ Intentando DOCUMENT_TEXT_DETECTION...');
      
      const [documentResult] = await client.documentTextDetection({
        image: {
          source: {
            imageUri: imageUrl,
          },
        },
        imageContext: {
          languageHints: ['es', 'en'], // Ayuda a la API a reconocer idiomas espec√≠ficos
          textDetectionParams: {
            enableTextDetectionConfidenceScore: true,
            // advancedOcrOptions: ['LEGACY_LAYOUT'] // Considerar probar sin esto o con otras opciones si LEGACY_LAYOUT no da buenos resultados.
          },
        },
      });

      console.log('‚úÖ DOCUMENT_TEXT_DETECTION completado.');
      
      // Debug: Analizar la respuesta de DOCUMENT_TEXT_DETECTION
      console.log('üîç Analizando respuesta de DOCUMENT_TEXT_DETECTION:');
      console.log('  - fullTextAnnotation existe:', !!documentResult.fullTextAnnotation);
      console.log('  - fullTextAnnotation.text longitud:', documentResult.fullTextAnnotation?.text?.length || 0);
      console.log('  - textAnnotations longitud:', documentResult.textAnnotations?.length || 0);
      if (documentResult.textAnnotations && documentResult.textAnnotations.length > 0) {
        console.log('  - textAnnotations[0].description longitud:', documentResult.textAnnotations[0]?.description?.length || 0);
      }
      
      if (documentResult.fullTextAnnotation?.text) {
        extractedText = documentResult.fullTextAnnotation.text;
        detectionMethod = 'document_detection_full';
        console.log(`‚úÖ Texto extra√≠do con fullTextAnnotation (${detectionMethod}):`, extractedText.length, 'caracteres');
      } else if (documentResult.textAnnotations?.[0]?.description) {
        // Fallback si fullTextAnnotation est√° vac√≠o pero textAnnotations[0] tiene algo
        extractedText = documentResult.textAnnotations[0].description;
        detectionMethod = 'document_detection_annotations';
        console.log(`‚úÖ Texto extra√≠do con textAnnotations[0] (${detectionMethod}):`, extractedText.length, 'caracteres');
      }

      // Debug: Mostrar las primeras anotaciones de texto si existen
      if (documentResult.textAnnotations && documentResult.textAnnotations.length > 0) {
        console.log('üìù Primeras 3 anotaciones de texto (DOCUMENT_TEXT_DETECTION):');
        documentResult.textAnnotations.slice(0, 3).forEach((annotation, idx) => {
          console.log(`  ${idx}: "${(annotation.description || '').substring(0,100)}..." (confianza: ${annotation.confidence || 'N/A'})`);
        });
      }

    } catch (docError) {
      console.error('‚ùå Error en DOCUMENT_TEXT_DETECTION:', docError);
    }

    // ===== ESTRATEGIA 2: TEXT_DETECTION (Fallback para texto m√°s disperso o si DOCUMENT_TEXT_DETECTION fall√≥) =====
    // Intentar si la primera estrategia no extrajo texto o muy poco (ej. menos de 50 caracteres)
    if (!extractedText || extractedText.length < 50) {
      console.log('üî§ Texto actual corto o nulo. Intentando TEXT_DETECTION tradicional...');
      try {
        const [textResult] = await client.textDetection({
          image: {
            source: {
              imageUri: imageUrl,
            },
          },
          imageContext: {
            languageHints: ['es', 'en', 'es-ES', 'en-US'], // M√°s hints pueden ayudar
          },
        });

        console.log('‚úÖ TEXT_DETECTION completado.');
        console.log('üîç Analizando respuesta de TEXT_DETECTION:');
        console.log('  - textAnnotations longitud:', textResult.textAnnotations?.length || 0);
        if (textResult.textAnnotations && textResult.textAnnotations.length > 0) {
          console.log('  - textAnnotations[0].description longitud:', textResult.textAnnotations[0]?.description?.length || 0);
        }

        if (textResult.textAnnotations?.[0]?.description) {
          const textFromTextDetection = textResult.textAnnotations[0].description;
          console.log('üìè Texto de TEXT_DETECTION:', textFromTextDetection.length, 'caracteres');
          
          // Usar el texto m√°s largo entre el actual y este nuevo resultado
          if (textFromTextDetection.length > extractedText.length) {
            extractedText = textFromTextDetection;
            detectionMethod = 'text_detection_full';
            console.log(`‚úÖ Usando resultado de TEXT_DETECTION (m√°s largo): ${extractedText.length} caracteres`);
          }
        }
      } catch (textError) {
        console.error('‚ùå Error en TEXT_DETECTION:', textError);
      }
    }

    // ===== ESTRATEGIA 3: ANNOTATE_IMAGE con M√öLTIPLES FEATURES (Fallback m√°s robusto) =====
    // Intentar si el texto sigue siendo corto (ej. menos de 100 caracteres)
    if (!extractedText || extractedText.length < 100) {
      console.log('üéØ Texto actual a√∫n corto. Intentando detecci√≥n con m√∫ltiples features (annotateImage)...');
      try {
        const [multiResult] = await client.annotateImage({
          image: {
            source: {
              imageUri: imageUrl,
            },
          },
          features: [
            { type: 'DOCUMENT_TEXT_DETECTION', maxResults: 1, model: 'builtin/latest' }, // Pedir expl√≠citamente el modelo m√°s reciente
            { type: 'TEXT_DETECTION', maxResults: 1 }, // maxResults para TEXT_DETECTION aqu√≠ se refiere al n√∫mero de bloques de texto. 1 para el texto completo.
          ],
          imageContext: {
            languageHints: ['es', 'en', 'es-ES', 'en-US'],
            textDetectionParams: {
              enableTextDetectionConfidenceScore: true,
            },
          },
        });

        console.log('‚úÖ Detecci√≥n m√∫ltiple (annotateImage) completada.');
        console.log('üîç Analizando respuesta de annotateImage:');
        console.log('  - fullTextAnnotation existe:', !!multiResult.fullTextAnnotation);
        console.log('  - fullTextAnnotation.text longitud:', multiResult.fullTextAnnotation?.text?.length || 0);
        console.log('  - textAnnotations longitud:', multiResult.textAnnotations?.length || 0);
         if (multiResult.textAnnotations && multiResult.textAnnotations.length > 0) {
          console.log('  - textAnnotations[0].description longitud:', multiResult.textAnnotations[0]?.description?.length || 0);
        }
        
        // Priorizar fullTextAnnotation si existe y es m√°s largo
        if (multiResult.fullTextAnnotation?.text && multiResult.fullTextAnnotation.text.length > extractedText.length) {
          extractedText = multiResult.fullTextAnnotation.text;
          detectionMethod = 'multi_document_full_text';
          console.log(`‚úÖ Usando fullTextAnnotation de annotateImage (${detectionMethod}): ${extractedText.length} caracteres`);
        } 
        // Luego probar textAnnotations[0].description si es m√°s largo
        else if (multiResult.textAnnotations?.[0]?.description && multiResult.textAnnotations[0].description.length > extractedText.length) {
          extractedText = multiResult.textAnnotations[0].description;
          detectionMethod = 'multi_text_annotations';
          console.log(`‚úÖ Usando textAnnotations[0] de annotateImage (${detectionMethod}): ${extractedText.length} caracteres`);
        }

      } catch (multiError) {
        console.error('‚ùå Error en detecci√≥n m√∫ltiple (annotateImage):', multiError);
      }
    }
    
    // ===== ESTRATEGIA 4: FORZAR DESCARGA Y PROCESAMIENTO LOCAL (Si la URL es problem√°tica) =====
    // Intentar si el texto sigue siendo muy corto (ej. menos de 50 caracteres) y podr√≠a haber problemas con la accesibilidad de la URL
    if (!extractedText || extractedText.length < 50) {
        console.log('üì• Texto a√∫n corto. Intentando descarga directa de imagen y procesamiento como base64...');
        try {
            const imageResponse = await fetch(imageUrl);
            if (imageResponse.ok) {
                const imageBuffer = await imageResponse.arrayBuffer();
                const base64Image = Buffer.from(imageBuffer).toString('base64');
                
                console.log('üì∏ Imagen descargada, tama√±o:', imageBuffer.byteLength, 'bytes. Procesando con documentTextDetection...');
                
                const [base64Result] = await client.documentTextDetection({
                    image: { 
                        content: base64Image // Enviar contenido como base64
                    },
                    imageContext: {
                        languageHints: ['es', 'en'],
                         textDetectionParams: {
                            enableTextDetectionConfidenceScore: true,
                        },
                    }
                });

                console.log('‚úÖ Detecci√≥n con imagen base64 completada.');
                console.log('üîç Analizando respuesta de detecci√≥n base64:');
                console.log('  - fullTextAnnotation existe:', !!base64Result.fullTextAnnotation);
                console.log('  - fullTextAnnotation.text longitud:', base64Result.fullTextAnnotation?.text?.length || 0);

                if (base64Result.fullTextAnnotation?.text) {
                    const base64Text = base64Result.fullTextAnnotation.text;
                    console.log('üìè Texto de imagen base64:', base64Text.length, 'caracteres');
                    
                    if (base64Text.length > extractedText.length) {
                        extractedText = base64Text;
                        detectionMethod = 'base64_document_detection';
                        console.log(`‚úÖ Usando resultado de imagen base64 (${detectionMethod}): ${extractedText.length} caracteres`);
                    }
                }
            } else {
                console.warn(`‚ö†Ô∏è No se pudo descargar la imagen de ${imageUrl}. Estado: ${imageResponse.status}`);
            }
        } catch (base64Error) {
            console.error('‚ùå Error en procesamiento de imagen base64:', base64Error);
        }
    }


    // ===== VALIDACI√ìN FINAL DEL TEXTO EXTRA√çDO =====
    console.log('\nüîç VALIDACI√ìN FINAL:');
    console.log('  - Texto extra√≠do:', !!extractedText);
    console.log('  - Longitud:', extractedText.length);
    console.log('  - M√©todo usado final:', detectionMethod || 'Ninguno efectivo');

    if (!extractedText || extractedText.trim().length === 0) {
      console.log('‚ùå No se pudo extraer texto de la imagen despu√©s de todos los intentos.');
      return NextResponse.json(
        { 
          error: 'No se pudo extraer texto de la imagen. Verifica que la imagen tenga texto legible y que la URL sea accesible.',
          debugInfo: {
            imageUrl: imageUrl,
            attemptsMade: ['documentTextDetection', 'textDetection', 'annotateImage_multi', 'base64_document_detection'],
            finalDetectionMethod: detectionMethod,
          }
        },
        { status: 404 }
      );
    }

    console.log('üìã TEXTO EXTRA√çDO FINAL:');
    console.log('----------------------------------------');
    console.log(extractedText.substring(0, 500) + (extractedText.length > 500 ? '...' : '')); // Mostrar solo una parte si es muy largo
    console.log('----------------------------------------');

    const lines = extractedText.split('\n').filter(line => line.trim().length > 0);
    const words = extractedText.split(/\s+/).filter(word => word.trim().length > 0);
    
    console.log('üìä Estad√≠sticas detalladas:');
    console.log('  - Longitud total:', extractedText.length);
    console.log('  - L√≠neas v√°lidas:', lines.length);
    console.log('  - Palabras:', words.length);
    
    // Limpieza suave del texto
    const cleanedText = extractedText
      .replace(/\n{3,}/g, '\n\n') // Reducir m√∫ltiples saltos de l√≠nea a m√°ximo dos
      .replace(/ {2,}/g, ' ')     // Reducir m√∫ltiples espacios a uno solo
      .trim();

    const processingTime = Date.now() - startTime;
    console.log(`‚úÖ EXTRACCI√ìN COMPLETADA EXITOSAMENTE en ${processingTime}ms usando ${detectionMethod}`);

    return NextResponse.json({
      text: cleanedText,
      // confidence: ..., // Omitido ya que no hay un score de confianza agregado simple y fiable.
      method: detectionMethod,
      originalLength: extractedText.length,
      cleanedLength: cleanedText.length,
      processingTimeMs: processingTime,
      debugInfo: {
        linesExtracted: lines.length,
        wordsExtracted: words.length,
        firstFewLines: lines.slice(0, 5).map(line => line.trim()),
        imageUrl: imageUrl,
      }
    });

  } catch (error: any) {
    const processingTime = Date.now() - startTime;
    console.error(`‚ùå ERROR GENERAL EN LA RUTA DE EXTRACCI√ìN DE TEXTO (${processingTime}ms):`, error);
    
    let errorMessage = 'Error desconocido procesando la imagen con Google Vision AI.';
    let errorStatus = 500;

    if (error.message) {
        if (error.message.includes('credentials') || error.message.includes('PERMISSION_DENIED')) {
            errorMessage = 'Error de autenticaci√≥n o permisos con Google Cloud Vision. Verifica las credenciales y los permisos del service account.';
            errorStatus = error.message.includes('credentials') ? 401 : 403;
        } else if (error.message.includes('quota') || error.message.includes('RESOURCE_EXHAUSTED')) {
            errorMessage = 'L√≠mite de API excedido en Google Vision AI o recurso agotado.';
            errorStatus = 429;
        } else if (error.message.includes('Could not fetch image')) {
            errorMessage = 'No se pudo acceder a la imagen desde la URL proporcionada. Verifica que la URL sea p√∫blica y correcta.';
            errorStatus = 400;
        } else if (error.message.includes('Invalid image URI')) {
            errorMessage = 'La URL de la imagen no es v√°lida.';
            errorStatus = 400;
        } else {
            errorMessage = error.message; // Usar el mensaje de error original si no es uno de los espec√≠ficos
        }
    }
    
    return NextResponse.json(
      { 
        error: errorMessage,
        details: error.details || (error instanceof Error ? error.stack : 'No additional details'),
        processingTimeMs: processingTime 
      },
      { status: errorStatus }
    );
  }
}
